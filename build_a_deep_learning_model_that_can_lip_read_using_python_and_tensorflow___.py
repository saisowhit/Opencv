# -*- coding: utf-8 -*-
"""Build a Deep Learning Model that can LIP READ using Python and Tensorflow | .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GLIuvQ6UBRVL6_DGxm2b_u39QdyXIVHE
"""

!pip3 install imageio

import imageio
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import PIL
from tensorflow.keras import layers
import time
from IPython import display
import cv2

physical_devices=tf.config.experimental.list_physical_devices('GPU')
print("Num GPUs Available: ", len(physical_devices))

## Building Data Load Functions

vocab=[x for x in "abcdefghijklmnopqrstuwxyz123"]
char_to_num=tf.keras.layers.StringLookup(vocabulary=vocab,oov_token="")
num_to_char=tf.keras.layers.StringLookup(vocabulary=char_to_num.get_vocabulary(),oov_token="",invert=True)
print(f'the vocabulary is {char_to_num.get_vocabulary()}' f"(size={char_to_num.vocabulary_size()})")

char_to_num(['n','i','c','k'])
num_to_char([14,9,3,1])
chart_to_num.get_vocabulary()

def load_alignmen(path):
  with open(path,'r') as f:
    lines=f.readlines()
  tokens=[]
  for line in lines:
    line=line.split()
    if lines[2]!='sil':
      token
  return char_to_num(tf.reshape(tf.string.unicode_split(tokens,input_encoding="")))

def load_data()

test_path='.\\data\\s1\\bba16n.mpg'

frames,alignments=load_data(tf.convert_to_tensor(test_path).numpy().decode('utf-8'))

plt.imshow(frames[40])

print([bytes.decode(x) for x in num_to_char(alignments.numpy()).numpy()])

tf.string.reduce_join([bytes.decode(x) for x in num_to_char(alignments.numpy()).numpy()])

def mappable_function(path):
  result=tf.py_function(load_data,[path],(tf.float32,tf.int64))
  return result

## create a data pipeline

data=tf.data.Dataset.list_files('./data/s1/*.mpg')
data=data.shuffle(500)
data=data.map(mappable_function)
data=data.padded_batch(2,padded_shapes=([75,NONE,NONE,NONE]))
data=data.prefetch(tf.data.AUTOTUNE)
train=data.take(int(len(data)*0.8))
test=data.skip(int(len(data)*0.8))

frames,alignment=data.as_numpy_iterator().next()
alignments

len(frames)

test=data.as_numpy_iterator()
val=test.next(); val[0]
imageio.mimsave('./animation.gif',val[0],fs=10)

plt.imshow(val[0][0][35]) ## first zero reference video, second 0 referes the first vide out of the batch,return the first frame in the video

tf.strings.reduce_join([num_to_char(word) for word in val[1][0]])

def load_video(path):
  cap=cv2.VideoCapture(path)
  frames=[]
  for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):
    ret,frame=cap.read
    frame=tf.image.rgb_to_grayscale(frame)
    frame=tf.image.resize(frame,(120,120))
    frames.append(frame)
  cap.release()
  mean=tf.math.reduce_mean(frames)
  std=tf.math.reduce_std(tf.cast(frames,tf.float32))
  return tf.cast((frames-mean)/std,tf.float32)

## Design the deep Neural Network

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation,Conv3D,MaxPool3D,Flatten,LSTM
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler

model=Sequential()
model.add(Conv3D(128,3,input_shape=(75,46,140,1),padding='same'))
model.add(Activation('relu'))
model.add(MaxPool3D((1,2,2)))
model.add(Conv3D(64,3,padding='same'))
model.add(Activation('relu'))
model.add(MaxPool3D((1,2,2)))
model.add(Conv3D(75,3,padding='same'))
model.add(  Activation('relu'))
model.add(MaxPool3D((1,2,2)))
model.add(TimeDistributed(Flatten()))
model.add(Bidirectional(LSTM(128,kernel_initializer='Orthogonal',return_sequences=True)))
model.add(Dropout(0.5))
model.add(Bidirectional(LSTM(128,kernel_initializer='Orthogonal',return_sequences=True)))
model.add(Dropout(0.5))
model.add(Dense(char_to_num.vocabulary_size()+1,kernel_initializer='he_normal',activation='softmax'))

model.summary()

yhat=model.predict(val[0])

tf.strings.reduce_join([num_to_char(tf.argmax(word)) for word in yhat[1]])

char_to_num.vocab_size()

## setup  training options and Train



df CTCloss(y_true,y_pred):
batch_len=tf.cast(tf.shape(y_true)[0],dtype="int64")
input_length=tf.cast(tf.shape(y_pred)[1],dtype="int64")
label_length=tf.cast(tf.shape(y_true)[1],dtype="int64")
input_length=input_length*tf.ones(shape=(batch_len,1),dtype="int64")
label_length=label_length*tf.ones(shape=(batch_len,1),dtype="int64")
loss=tf.keras.backend.ctc_batch_cost(y_true,y_pred,input_length,label_length)
return loss

class ProduceExample(tf.keras.callbacks.Callback):
  def __init__(self,dataset):
    self.dataset=dataset.as_numpy_iterator()
  def on_epoch_end(self,epoch,logs=None):
    data=self.dataset.next()
    yhat=self.model.predict(data[0])
    decoded=
    for x in range(len( yhat)):
      print('Original',tf.string.reduce_join([vocab(word)+'' for word in data[1][x]]))
      print('prediction',tf.string.reduce_join([vocab(word)+'' for word in yhat[x]]))
      print('~'*100)

model.compile(optimizer=Adam(learning_rate=0.001),loss=CTCloss)



checkpoint_callback=

schedule_callback=LearningRateScheduler(scheduler)
example_callback=ProduceExample(data)
ModelCheckpoint(os.path.join('models','checkpoint'))
model.fit(data,epochs=1000,callbacks=[checkpoint_callback,schedule_callback,example_callback])

## Make prediction

url='http://drive.google.com/uc?id=1vWscXs4Vt0a_1IH1-ct2TCgXAZT-N3_Y'
output='checkpoint.zip'
gdown.download(url,output,quiet=False)
gdown.extractall('checkpoint.zip','models')

model.load_weights('models/checkpoint')
test_data=test.as_numpy_iterator()
tet_data.next()
yhat=model.predict(sample[0])
decoded=tf.keras.backend.ctc_decode(yhat,input_length=10*tf.ones(shape=(32,1)),greedy=True)[0][0].numpy()
print('~'*100,'PREDICTIONS')
[tf.strings.reduce_join([num_to_char(x) for x in y]).numpy().decode('utf-8') for y in decoded]

print('~'*100,'REAL TEXT')
[tf.strings.reduce_join([num_to_char(x) for x in SENTENCE]).numpy().decode('utf-8') for sentence in decoded]

decoded=tf.keras.backend.ctc_decode(yhat,input_length=10*tf.ones(shape=(32,1)),greedy=True)[0][0].numpy()
print('~'*100,'predictions')
[tf.strings.reduce_join([num_to_char(x) for x in y]).numpy().decode('utf-8') for y in decoded]

## Test on a video

sample=load_data(tf.convert_to_tensor('data/s1/bba16n.mpg').numpy().decode('utf-8'))

yhat=model.predict(sample[0],axis=0)
decoded=tf.keras.backend.ctc_decode(yhat,input_length=10*tf.ones(shape=(1,1)),greedy=True)[0][0].numpy()

print('~'*100,'REAL TEXT')
[tf.strings.reduce_join([num_to_char(x) for x in SENTENCE]).numpy().decode('utf-8') for sentence in decoded]

decoded=tf.keras.backend.ctc_decode(yhat,input_length=10*tf.ones(shape=(32,1)),greedy=True)[0][0].numpy()
print('~'*100,'predictions')
[tf.strings.reduce_join([num_to_char(x) for x in y]).numpy().decode('utf-8') for y in decoded]